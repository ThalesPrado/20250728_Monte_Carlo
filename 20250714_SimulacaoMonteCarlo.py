import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pandas.plotting import lag_plot
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.tsa.stattools import acf
from scipy.stats import norm

st.title("üìò Introdu√ß√£o Te√≥rica + Simula√ß√£o Monte Carlo")

st.header("üéØ Intui√ß√£o Inicial: Estimando œÄ com Monte Carlo")

st.markdown(r"""
Monte Carlo √© uma t√©cnica que utiliza n√∫meros aleat√≥rios para simular fen√¥menos complexos.  
Vamos come√ßar estimando o valor de $œÄ$ com uma ideia cl√°ssica.

Imagine um **quadrado de lado 1** com um **quarto de c√≠rculo** dentro dele.  
Ao jogar "dardos aleat√≥rios" nesse quadrado, a propor√ß√£o dos que caem no c√≠rculo √©:

$$
\frac{\pi}{4} \Rightarrow \pi \approx 4 \cdot \frac{n_{\text{dentro}}}{n_{\text{total}}}
$$
""")

np.random.seed(10)
n = 10000
nc = 0
pi_values = []
x_in, y_in = [], []
x_out, y_out = [], []

for j in range(n):
    x, y = np.random.random(2)
    if x**2 + y**2 <= 1:
        nc += 1
        x_in.append(x)
        y_in.append(y)
    else:
        x_out.append(x)
        y_out.append(y)
    if (j+1) % 10 == 0:
        pi_values.append(4 * nc / (j+1))

fig2, ax2 = plt.subplots()
ax2.scatter(x_in, y_in, s=1, label='Dentro do c√≠rculo', color='blue')
ax2.scatter(x_out, y_out, s=1, label='Fora do c√≠rculo', color='gray')
circle = plt.Circle((0, 0), 1, color='red', fill=False)
ax2.add_artist(circle)
ax2.set_aspect('equal')
ax2.set_title('üéØ Disposi√ß√£o dos Pontos')
ax2.legend()
st.pyplot(fig2)

fig1, ax1 = plt.subplots()
ax1.plot(range(10, n+1, 10), pi_values, label='Estimativa de œÄ')
ax1.axhline(np.pi, color='r', linestyle='--', label='œÄ real')
ax1.set_title('üìà Converg√™ncia de œÄ')
ax1.set_xlabel('Simula√ß√µes')
ax1.set_ylabel('Estimativa')
ax1.legend()
ax1.grid(True)
st.pyplot(fig1)

st.markdown("""
# üî¢ Geradores Pseudoaleat√≥rios (PRNGs)
Computadores usam algoritmos determin√≠sticos para gerar n√∫meros "aleat√≥rios".  
Esses PRNGs simulam aleatoriedade, e sua qualidade impacta diretamente a precis√£o da simula√ß√£o de Monte Carlo.

## ‚öôÔ∏è M√©todos Cl√°ssicos
- **LCG**: f√≥rmula simples, mas pode gerar padr√µes.
- **von Neumann**: hist√≥rico, n√£o confi√°vel.
- **Mersenne Twister (NumPy)**: padr√£o moderno e confi√°vel.
""")

n_test = st.slider("Tamanho da amostra para teste estat√≠stico", 100, 5000, 1000, key="prng_teste")
np_vals = np.random.random(n_test)

fig, ax = plt.subplots()
lag_plot(pd.Series(np_vals), ax=ax)
ax.set_title("Lag Plot - NumPy (Mersenne Twister)")
st.pyplot(fig)

fig_acf, ax_acf = plt.subplots()
plot_acf(np_vals, lags=30, ax=ax_acf)
ax_acf.set_title("ACF - NumPy")
st.pyplot(fig_acf)

acf_np = acf(np_vals, nlags=1)[1]
st.markdown(f"""
### Coeficiente de Autocorrela√ß√£o (Lag 1)
- NumPy: `r = {acf_np:.4f}`
- Valores pr√≥ximos de 0 indicam falta de autocorrela√ß√£o logo os resultados s√£o independentes entre si e isso √© exatamente o que esperamos de uma simula√ß√£o Monte Carlo bem feita.""")

def runs_test(series):
    median = np.median(series)
    runs, n1, n2 = 0, 0, 0
    prev = None
    for val in series:
        curr = 'A' if val >= median else 'B'
        if curr != prev:
            runs += 1
        if curr == 'A':
            n1 += 1
        else:
            n2 += 1
        prev = curr
    expected = (2 * n1 * n2) / (n1 + n2) + 1
    std = np.sqrt((2 * n1 * n2 * (2*n1*n2 - n1 - n2)) / (((n1 + n2)**2) * (n1 + n2 - 1)))
    z = (runs - expected) / std if std > 0 else 0
    p = 2 * (1 - norm.cdf(abs(z)))
    return runs, expected, z, p

runs_np, exp_np, z_np, p_np = runs_test(np_vals)

st.markdown(f"""
### Runs Test (Teste de Aleatoriedade)
- Runs observados: `{runs_np}`
- Esperado: `{exp_np:.2f}`
- Estat√≠stica z: `{z_np:.2f}`  
- p-valor: `{p_np:.4f}`

#### Hip√≥teses:
- H‚ÇÄ: Os dados s√£o aleat√≥rios.
- H‚ÇÅ: Os dados n√£o s√£o aleat√≥rios.

Como o p-valor √© alto, n√£o rejeitamos H‚ÇÄ.  
A sequ√™ncia gerada pelo Mersenne Twister √© estatisticamente aleat√≥ria.
""")

st.markdown("""
## Conclus√£o Final
- O NumPy/Mersenne Twister passou em todos os testes estat√≠sticos.
- Os gr√°ficos confirmam aus√™ncia de padr√µes, autocorrela√ß√£o e vi√©s.
- Ele √©, portanto, adequado para simula√ß√µes de Monte Carlo.
""")

st.markdown(r"""
---
## Vis√£o Geral do Projeto
Este aplicativo demonstra o uso da **Simula√ß√£o de Monte Carlo** para calcular o pre√ßo unit√°rio de uma barra de prote√≠na considerando a incerteza nos custos de mat√©rias-primas.

Temas chaves da simula√ß√£o de Monte Carlo s√£o:
            
### 1. üßÆ Lei dos Grandes N√∫meros (LLN)
**Intui√ß√£o:** Quanto mais simula√ß√µes fazemos, mais est√°vel e confi√°vel ser√° a nossa estimativa de pre√ßo unit√°rio m√©dio.
            
**Exemplo:**  
Se jogar uma moeda 10 vezes, pode dar 7 caras. Mas se jogar 10.000 vezes, o n√∫mero de caras se aproxima de 50%.
            
**Lei dos Grandes N√∫meros (LLN):**
   √Ä medida que $N \to \infty$:
   $$
   \lim_{N \to \infty} \hat{E}[X] = E[X]
   $$
   Ou seja, a m√©dia das simula√ß√µes converge para o valor esperado verdadeiro com probabilidade 1 (converg√™ncia quase certa).
            
### 2. üîÑ Teorema Central do Limite (CLT)
**Intui√ß√£o:** Mesmo que cada pre√ßo simulado siga uma distribui√ß√£o diferente (normal ou triangular), a **m√©dia dos pre√ßos simulados** tende a formar uma curva de sino (distribui√ß√£o normal).

**Exemplo:**  
A distribui√ß√£o de pre√ßos de prote√≠na, cacau e a√ß√∫car pode variar, mas a m√©dia do pre√ßo da barra simula uma curva suave parecida com uma Gaussiana.

### 3. ‚è≥ Ergodicidade
**Intui√ß√£o:** Simular uma longa sequ√™ncia de cen√°rios √© equivalente a observar todos os cen√°rios poss√≠veis.

**Exemplo:**  
Ao simular 10.000 cen√°rios de custos, podemos entender o comportamento geral do pre√ßo mesmo sem testar **todas** as combina√ß√µes poss√≠veis.

### 4. üìâ Desigualdade de Chebyshev
**Intui√ß√£o:** A maioria das simula√ß√µes fica perto da m√©dia. Simula√ß√µes muito distantes s√£o raras.

        
$$
P\left(|X - \mu| \geq k\sigma\right) \leq \frac{1}{k^2}
$$

Isso tamb√©m implica que a **probabilidade de estar dentro de $k$ desvios padr√£o** da m√©dia √© **pelo menos**:

$$
P\left(|X - \mu| < k\sigma\right) \geq 1 - \frac{1}{k^2}
$$
            
**Exemplo:**  
Imaginemos que trabalhamos em uma loja de roupas e queremos analisar o pre√ßo m√©dio de venda das camisetas nos √∫ltimos 6 meses para ajudar a definir a faixa de pre√ßo ideal para os pr√≥ximos lan√ßamentos.
            
Com uma m√©dia dos pre√ßos de camisetas vendidas de ùúá = 60 e desvio padr√£o = 10. Temos P([|X - ùúá| >= k*]) >= 1 - (1 / k^2).
O que queremos responder aqui √© qual a probabilidade de que X esteja a uma dist√¢ncia maior ou igual a k desvios padr√£o da m√©dia.

Logo temos, P([|X - 60|] < 20) >= 1 - 1/4.
            
            P([|X - 60|] < 20) >= 0,75.
            
            -20 < |X - 60| < 20

            -20 + 60 < | X - 60 + 60 | < 20 + 60

            40 < |X| < 80

            P(40 < |X| < 80) >= 0,75

Pelo menos 75% pre√ßos est√£o entre 40 e 80, mesmo sem saber a forma da distribui√ß√£o de probabilidade dessa V.A.

---

## üßÆ Formula√ß√£o Matem√°tica de pre√ßos
O pre√ßo unit√°rio $P_u$ √© dado por:
$$
P_u = CMV \cdot (1 + M)
$$
Onde:
- $CMV$: Custo da Mercadoria Vendida se da pela soma dos custos de prote√≠na, a√ß√∫car, cacau e embalagem.
- $M$: Margem bruta desejada.

O $CMV$ detalhado √©:
$$
CMV_i = C_{\text{prote√≠na}, i} + C_{\text{a√ß√∫car}, i} + C_{\text{cacau}, i} + C_{\text{embalagem}, i}
$$

### Intui√ß√£o Matem√°tica
Em teoria das probabilidades, o **valor esperado** de uma vari√°vel aleat√≥ria $X$ √©:
$$
E[X] = \int x \cdot f(x)\,dx
$$
Na pr√°tica, usamos Monte Carlo para aproximar esse valor com uma m√©dia aritm√©tica de $N$ amostras independentes:
$$
\hat{E}[P_u] = \frac{1}{N} \sum_{i=1}^{N} P_{u,i}
$$

Ou seja simulei o pre√ßo N vezes e tirei a m√©dia. 
            
Se $N=5$, isso seria explicitamente:
$$
\hat{E}[P_u] = \frac{1}{5}(P_{u,1} + P_{u,2} + P_{u,3} + P_{u,4} + P_{u,5})
$$

onde cada $P_{u,i}$ √© o resultado da i-√©sima simula√ß√£o. Ou seja a simula√ß√£o de Monte Carlo nos ajuda a estimar o  pre√ßo mais prov√°vel da barra de prote√≠na, mesmo quando os custos variam muito. Em vez de depender de um √∫nico cen√°rio fixo, usamos milhares de cen√°rios poss√≠veis e fazemos a m√©dia deles.

1. **Defini√ß√£o de espa√ßo amostral $(\Omega, \mathcal{F}, P)$**:
   - $\Omega$: conjunto de todos os cen√°rios poss√≠veis (custos futuros dos insumos).
   - $\mathcal{F}$: conjunto de eventos (subconjuntos de $\Omega$). Uma V.A  √© simplesmente um n√∫mero que muda de forma imprevis√≠vel dentro de um certo padr√£o.
   - $P$: fun√ß√£o probabilidade que atribui chance a cada evento.

2. **Vari√°veis aleat√≥rias**:
   Cada custo (prote√≠na, cacau, a√ß√∫car, embalagem) √© modelado como uma fun√ß√£o aleat√≥ria:
   $$
   X: \Omega \to \mathbb{R}
   $$
   onde $X(\omega)$ √© o custo em um cen√°rio espec√≠fico $\omega$.
   Cada cen√°rio poss√≠vel (Œ©) leva a um valor num√©rico (‚Ñù)

3. **Valor esperado**:
   O valor esperado √© a m√©dia ponderada de todos os poss√≠veis resultados:
   $$
   E[X] = \int_{\Omega} X(\omega)\,dP(\omega)
   $$

---

## üìù Como Saber se a Estimativa √© Boa?
‚úîÔ∏è **A qualidade da estimativa depende de:**
- **N√∫mero de Simula√ß√µes ($N$):** quanto maior, mais est√°vel a m√©dia (gra√ßas √† LLN).
- **Desvio Padr√£o:** baixo desvio indica menor incerteza.
- **Intervalo [P5, P95]:** intervalo estreito significa maior confiabilidade. Esse intervalo cont√©m 90% dos pre√ßos simulados.
- **Visualiza√ß√£o das Distribui√ß√µes:** valida se as suposi√ß√µes sobre volatilidade s√£o realistas.

""")

# --- Simula√ß√£o de Pre√ßo da Barra de Prote√≠na ---
st.markdown("---")
st.header("\U0001F52C Simula√ß√£o de Pre√ßo da Barra de Prote√≠na")

st.sidebar.header("\U0001F4C5 Par√¢metros de Entrada")
proteina_media = st.sidebar.number_input("M√©dia do pre√ßo da prote√≠na (R$/kg)", value=40.0)
proteina_sigma = st.sidebar.number_input("Desvio padr√£o da prote√≠na (R$/kg)", value=5.0)
proteina_peso = st.sidebar.number_input("Peso da prote√≠na por barra (kg)", value=0.03)
acucar_media = st.sidebar.number_input("M√©dia do pre√ßo do a√ß√∫car (R$/kg)", value=20.0)
acucar_sigma = st.sidebar.number_input("Desvio padr√£o do a√ß√∫car (R$/kg)", value=3.0)
acucar_peso = st.sidebar.number_input("Peso do a√ß√∫car por barra (kg)", value=0.02)
cacau_media = st.sidebar.number_input("M√©dia do pre√ßo do cacau (R$/kg)", value=25.0)
cacau_sigma = st.sidebar.number_input("Desvio padr√£o do cacau (R$/kg)", value=4.0)
cacau_peso = st.sidebar.number_input("Peso do cacau por barra (kg)", value=0.015)
emb_min = st.sidebar.number_input("Custo m√≠nimo da embalagem (R$/unidade)", value=0.5)
emb_mode = st.sidebar.number_input("Custo mais prov√°vel da embalagem (R$/unidade)", value=0.6)
emb_max = st.sidebar.number_input("Custo m√°ximo da embalagem (R$/unidade)", value=0.8)
margem = st.sidebar.slider("Margem bruta desejada (%)", 0, 100, 30) / 100
n_simulacoes = st.sidebar.number_input("N√∫mero de Simula√ß√µes", value=10000)

np.random.seed(42)
C_proteina = np.random.normal(proteina_media, proteina_sigma, n_simulacoes) * proteina_peso
C_acucar = np.random.normal(acucar_media, acucar_sigma, n_simulacoes) * acucar_peso
C_cacau = np.random.normal(cacau_media, cacau_sigma, n_simulacoes) * cacau_peso
C_embalagem = np.random.triangular(emb_min, emb_mode, emb_max, n_simulacoes)

CMV = C_proteina + C_acucar + C_cacau + C_embalagem
preco_unitario = CMV * (1 + margem)

# Converg√™ncia da m√©dia
convergencia = np.cumsum(preco_unitario) / (np.arange(n_simulacoes) + 1)
fig_conv, ax_conv = plt.subplots()
ax_conv.plot(convergencia, label='M√©dia acumulada')
ax_conv.axhline(np.mean(preco_unitario), color='red', linestyle='--', label='M√©dia final')
ax_conv.set_title('üìà Converg√™ncia da M√©dia Estimada')
ax_conv.set_xlabel('N√∫mero de Simula√ß√µes')
ax_conv.set_ylabel('Pre√ßo Estimado (R$)')
ax_conv.legend()
st.pyplot(fig_conv)

# Pesos relativos
componentes = ['Prote√≠na', 'A√ß√∫car', 'Cacau', 'Embalagem']
medias = [np.mean(C_proteina), np.mean(C_acucar), np.mean(C_cacau), np.mean(C_embalagem)]
pesos = np.array(medias) / np.mean(CMV)

fig_pesos, ax_pesos = plt.subplots()
ax_pesos.pie(pesos, labels=componentes, autopct='%1.1f%%', startangle=90)
ax_pesos.set_title('üìä Participa√ß√£o no Custo Total (CMV)')
st.pyplot(fig_pesos)

# Estat√≠sticas
media_preco = np.mean(preco_unitario)
desvio_preco = np.std(preco_unitario)
p5_preco = np.percentile(preco_unitario, 5)
p95_preco = np.percentile(preco_unitario, 95)

st.subheader("üìä Estat√≠sticas da Simula√ß√£o")
st.write(f"**Pre√ßo M√©dio Estimado:** R$ {media_preco:.2f}")
st.write(f"**Desvio Padr√£o:** R$ {desvio_preco:.2f}")
st.write(f"**5¬∫ Percentil (P5):** R$ {p5_preco:.2f}")
st.write(f"**95¬∫ Percentil (P95):** R$ {p95_preco:.2f}")

fig_hist, ax_hist = plt.subplots()
ax_hist.hist(preco_unitario, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
ax_hist.axvline(media_preco, color='red', linestyle='--', label='M√©dia')
ax_hist.axvline(p5_preco, color='green', linestyle='--', label='P5')
ax_hist.axvline(p95_preco, color='orange', linestyle='--', label='P95')
ax_hist.set_title('Distribui√ß√£o do Pre√ßo Unit√°rio Simulado')
ax_hist.set_xlabel('Pre√ßo Unit√°rio (R$)')
ax_hist.set_ylabel('Frequ√™ncia')
ax_hist.legend()
st.pyplot(fig_hist)

# ACF e Lag Plot
st.subheader("üìà ACF, Lag Plot e Autocorrela√ß√£o")
fig_lag, ax_lag = plt.subplots()
lag_plot(pd.Series(preco_unitario), ax=ax_lag)
ax_lag.set_title("Lag Plot - Pre√ßo Simulado")
st.pyplot(fig_lag)

fig_acf_sim, ax_acf_sim = plt.subplots()
plot_acf(preco_unitario, lags=30, ax=ax_acf_sim)
ax_acf_sim.set_title("ACF - Pre√ßo Simulado")
st.pyplot(fig_acf_sim)

acf_1 = acf(preco_unitario, nlags=1)[1]
st.markdown(f"### Autocorrela√ß√£o (lag 1): `r = {acf_1:.4f}`")

# Runs Test
st.subheader("üß™ Runs Test - Aleatoriedade dos Pre√ßos")
def runs_test(series):
    median = np.median(series)
    runs, n1, n2 = 0, 0, 0
    prev = None
    for val in series:
        curr = 'A' if val >= median else 'B'
        if curr != prev:
            runs += 1
        if curr == 'A':
            n1 += 1
        else:
            n2 += 1
        prev = curr
    expected = (2 * n1 * n2) / (n1 + n2) + 1
    std = np.sqrt((2 * n1 * n2 * (2*n1*n2 - n1 - n2)) / (((n1 + n2)**2) * (n1 + n2 - 1)))
    z = (runs - expected) / std if std > 0 else 0
    p = 2 * (1 - norm.cdf(abs(z)))
    return runs, expected, z, p

r, e, z, p = runs_test(preco_unitario)
st.markdown(f"""
- Runs observados: `{r}`
- Esperado: `{e:.2f}`
- Estat√≠stica z: `{z:.2f}`
- **p-valor**: `{p:.4f}`

#### Hip√≥teses:
- **H‚ÇÄ:** Os pre√ßos simulados s√£o aleat√≥rios.
- **H‚ÇÅ:** Os pre√ßos simulados **n√£o** s√£o aleat√≥rios.

‚úÖ Como o **p-valor √© alto**, n√£o rejeitamos H‚ÇÄ.  
Os pre√ßos simulados mostram aleatoriedade estatisticamente aceit√°vel.
""")
